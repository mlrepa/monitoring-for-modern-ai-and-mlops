{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05f00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "import mlflow \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80a25445",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://0.0.0.0:5001\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPEN API key:\")\n",
    "\n",
    "openai = OpenAI()\n",
    "mlflow.set_experiment(\"assignment-5-evaluate-llm\")\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5da59303",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow.trace\n",
    "def evaluation(prompt: str, deck_data: any):\n",
    "    \"\"\"\n",
    "    Function to evaluate a Clash Royale deck using OpenAI API.\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation_prompt = \"\"\"\n",
    "#  Identity\n",
    "You are a professional Clash Royale coach and deck analyst.\n",
    "\n",
    "#  Instructions\n",
    "Your task is to evaluate any 8-card Clash Royale deck using a structured and in-depth scoring system inspired by Deckshop. Your evaluation must include both **numeric ratings** and **detailed explanations** based on:\n",
    "\n",
    "- Individual card roles\n",
    "- Meta relevance\n",
    "- Synergy potential (classic + emerging combos)\n",
    "- Overall deck balance\n",
    "- Spell composition\n",
    "\n",
    "---\n",
    "\n",
    " **Rate the deck from 1 to 10** in the following categories:\n",
    "\n",
    "1. **Overall Power** – How viable the deck is across ladder, global tournaments, and special challenges.\n",
    "2. **Defense** – Assess how well the deck can handle:\n",
    "   -  Air threats (e.g., Minions, Balloon, Lava Hound)\n",
    "   -  Swarms (e.g., Skeleton Army, Bats)\n",
    "   - Tanks (e.g., Giant, Royal Giant, Golem)\n",
    "   - Splash resistance\n",
    "   -  Spell defense (e.g., vs Goblin Barrel, Graveyard)\n",
    "3. **Attack** – Consider:\n",
    "   - Presence of a clear **win condition**\n",
    "   - Strength of **support troops**\n",
    "   - **Breakthrough ability** (vs buildings, swarms)\n",
    "   - **Pressure** (dual-lane, bridge spam, counter-push)\n",
    "4. **Synergy** – Evaluate:\n",
    "   - Known combo effectiveness (e.g., Miner + Poison, Hog + Ice Spirit)\n",
    "   - Cycle consistency and elixir pacing\n",
    "   - Spell synergy (e.g., Log + Fireball)\n",
    "   - Role diversity (tank, DPS, splash, control)\n",
    "   - Potential for **new synergy discovery**\n",
    "5. **Versatility** – Rate:\n",
    "   - Matchups vs all major archetypes (siege, bait, beatdown, etc.)\n",
    "   - Recovery ability after a bad rotation\n",
    "   - Adaptability in both ladder and competitive modes\n",
    "   - Flexibility for switching between offense and defense\n",
    "6. difficulty of the deck:\n",
    "   - how easy it is to play this deck on different levels and how much experience is needed\n",
    "   - 1 being the easiest and 10 being the hardest only pros can play\n",
    "\n",
    "---\n",
    "\n",
    "**Average Elixir Cost**\n",
    "Return the float as provided (e.g., `3.50`).\n",
    "\n",
    "---\n",
    "\n",
    " **Card Role & Spell Balance Guidelines**\n",
    "\n",
    "Spells are divided into:\n",
    "-  **Small Spells** (): Log, Zap, Snowball, Barbarian Barrel, Arrows, Goblin Curse\n",
    "-  **Big Spells** (): Fireball, Poison, Lightning, Rocket, Earthquake\n",
    "\n",
    " Every well-balanced deck **usually  includes one small and one big spell.**\n",
    "\n",
    "\n",
    "---\n",
    " **Deck Usage**\n",
    "-in the end of the output, yu must give it as a comments:\n",
    "1 liner explanation of where and when and how to use each card\n",
    "-saying which cards are defenders, which ones are win condintions and which ones are support\n",
    "format should be:\n",
    "-card 1 explanation\n",
    "-card 2 explanation, etc.\n",
    "\n",
    " **Deck Archetype Classification**\n",
    "Choose the most accurate one:\n",
    "\n",
    "- Beatdown\n",
    "- Hybrid Beatdown\n",
    "- Sparky Beatdown\n",
    "- Air Beatdown\n",
    "- Control\n",
    "- Graveyard Control\n",
    "- Royal Giant Control\n",
    "- Splashyard\n",
    "- Cycle\n",
    "- Hog Cycle\n",
    "- Mega Minion Cycle\n",
    "- Miner Wall Breakers Cycle\n",
    "- Bridge Spam\n",
    "- Siege\n",
    "- Spell Bait\n",
    "- Off-Meta / Experimental\n",
    "- Troll / Meme Deck\n",
    "\n",
    "---\n",
    "\n",
    " **Deck Input Format (JSON)**:\n",
    "\n",
    "Return a JSON object with these fields:\n",
    "- deck_name: string\n",
    "- average_elixir: number\n",
    "- cards: list of strings (card names)\n",
    "- comment: string (markdown summary of the deck’s analysis, including key points, pros, and cons)\n",
    "\n",
    "Note: Keep `comment` brief—limit to 6 or 7 sentences max.\n",
    "\n",
    "**Evaluate this deck:**\n",
    "\n",
    "{{deck_json}}\n",
    "\n",
    "- After evaluating the deck, give the comment of explanation of strong and weak sides of deck, synergies, and how, where and when spawn the cards. Also say which are win condintions of the deck, what is synergetic duo/trios and etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Output JSON Format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"overall\": X,\n",
    "  \"defense\": X,\n",
    "  \"attack\": X,\n",
    "  \"synergy\": X,\n",
    "  \"versatility\": X,\n",
    "  \"avg_elixir\": X.XX,\n",
    "  \"difficulty\": X,\n",
    "  \"deck_type\": \"Deck Archetype\",\n",
    "  \"comments\": \"format the output as said here for some given deck:  **Deck Usage**\n",
    "  comments:\n",
    "Hog Rider - Win condition, apply pressure, punish opponent's mistakes\n",
    "Mega Knight - Tank and splash damage, counter big pushes\n",
    "Firecracker - Support, splash damage, anti-air defense\n",
    "Skeletons - Cycle, distract, chip damage\n",
    "Ice Spirit - Cycle, freeze, support Hog pushes\n",
    "Tesla - Defensive building, distracts, counters tanks\n",
    "Fireball - Spell, support for Hog pushes, eliminate swarms\n",
    "The Log - Spell, clear swarms, push back units, support Hog pushes\n",
    "\n",
    "This Hog Cycle Control deck excels in defense, with the Mega Knight and Tesla providing sturdy defense against various threats. The Hog Rider serves as the primary win condition, applying pressure and punishing mistakes. Firecracker adds splash damage and anti-air support, complementing the\n",
    "Hog pushes. The deck has good synergy and cycle consistency, allowing for quick and effective gameplay. The versatile card selection enables adaptability in different matchups and scenarios, making it a solid choice for ladder and competitive play.\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    # Load the prompt instructions from a markdown file\n",
    "    evaluation_prompt = evaluation_prompt.replace(\n",
    "        \"{{deck_json}}\",\n",
    "        json.dumps(deck_data),\n",
    "    )\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a Clash Royale deck evaluation assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": evaluation_prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = completion.choices[0].message.content\n",
    "    print(\"Raw model output:\", repr(content))\n",
    "\n",
    "    # Attempt to parse the content as JSON\n",
    "    try:\n",
    "        parsed = json.loads(content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse evaluation response as JSON: {e}\")\n",
    "        print(\"Raw content:\", content)\n",
    "        raise\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"user prompt\", prompt)\n",
    "        mlflow.log_param(\"deck_name\", deck_data[\"deck_name\"])\n",
    "        mlflow.log_param(\"average_elixir_cost\", deck_data[\"average_elixir_cost\"])\n",
    "        mlflow.log_param(\"cards\", deck_data[\"cards\"])\n",
    "\n",
    "        mlflow.log_metric(\"eval_overall\", parsed[\"overall\"])\n",
    "        mlflow.log_metric(\"eval_defense\", parsed[\"defense\"])\n",
    "        mlflow.log_metric(\"eval_attack\", parsed[\"attack\"])\n",
    "        mlflow.log_metric(\"eval_synergy\", parsed[\"synergy\"])\n",
    "        mlflow.log_metric(\"eval_versatility\", parsed[\"versatility\"])\n",
    "        mlflow.log_metric(\"eval_avg_elixir\", parsed[\"avg_elixir\"])\n",
    "        mlflow.log_metric(\"eval_difficulty\", parsed[\"difficulty\"])\n",
    "\n",
    "\n",
    "@mlflow.trace\n",
    "def ask_agent(user_input: str):\n",
    "    \"\"\"\n",
    "    Function to ask for deck advice from the OpenAI API.\n",
    "    \"\"\"\n",
    "\n",
    "    instruction_prompt = \"\"\"\n",
    "## Identity\n",
    "You are a Clash Royale deck-building assistant. Provide concise, practical deck-building advice.\n",
    "    \n",
    "___\n",
    "\n",
    "## Instructions\n",
    "- Output only viable decks.\n",
    "- Consider user's available cards if provided.\n",
    "- Reference meta decks only if relevant.\n",
    "- Include average elixir cost and key stats.\n",
    "- Avoid unnecessary explanations.\n",
    "- Output must be valid JSON matching the provided schema.\n",
    "\n",
    "___\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Return a JSON object with these fields:\n",
    "- deck_name: string\n",
    "- average_elixir_cost: number\n",
    "- cards: list of strings (card names)\n",
    "- comment: string (markdown summary of the deck’s analysis, including key points, pros, and cons)\n",
    "\n",
    "Note: Keep `comment` brief—limit to 6 or 7 sentences max.\n",
    "\n",
    "___\n",
    "\n",
    "## Current Meta Decks\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\"deck_name\": \"Giant Wizard Control\", \"average_elixir_cost\": 3.9, \"cards\": [ \"Giant\", \"Mini P.E.K.K.A\", \"Wizard\", \"Arrows\", \"Bomber\", \"Musketeer\", \"Valkyrie\", \"Electro Spirit\" ]},\n",
    "    {\"deck_name\": \"Anti-Swarm Control\", \"average_elixir_cost\": 3.6, \"cards\": [ \"Knight\", \"Archers\", \"Wizard\", \"Arrows\", \"Bomber\", \"Mini P.E.K.K.A\", \"Giant\", \"Fireball\" ]},\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": instruction_prompt },\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        text={\"format\": {\"type\": \"json_object\"}}\n",
    "    )\n",
    "    content = response.output_text\n",
    "    deck_data = json.loads(content)\n",
    "\n",
    "    evaluation(user_input, deck_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "652d5062",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLocalProtocolError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:86\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     84\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msend_request_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     85\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33msend_request_body\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:144\u001b[39m, in \u001b[36mHTTP11Connection._send_request_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    142\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mwrite\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions({h11.LocalProtocolError: LocalProtocolError}):\n\u001b[32m    145\u001b[39m     event = h11.Request(\n\u001b[32m    146\u001b[39m         method=request.method,\n\u001b[32m    147\u001b[39m         target=request.url.target,\n\u001b[32m    148\u001b[39m         headers=request.headers,\n\u001b[32m    149\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mLocalProtocolError\u001b[39m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLocalProtocolError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/openai/_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mLocalProtocolError\u001b[39m: Illegal header value b'Bearer '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mask_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      2\u001b[39m \u001b[33;43mI need a deck for Hog Cycle Control. I have the following cards available: Mega Knight, Firecracker, Tesla, Hog Rider, Skeletons, Ice Spirit, Fireball, The Log.\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[33;43mPlease provide a deck that is effective in the current meta, with a focus on Hog Cycle Control.\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m ask_agent(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mI want to counter a Giant deck with a Hog Cycle Control deck. I have the following cards available: Mega Knight, Firecracker, Tesla, Hog Rider, Skeletons, Ice Spirit, Fireball, The Log.\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mPlease provide a deck that is effective in the current meta, with a focus on Hog Cycle Control.\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     11\u001b[39m ask_agent(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33mI need a deck for Wizard Control. I have the following cards available: Giant, Mini P.E.K.K.A, Wizard, Arrows, Bomber, Musketeer, Valkyrie, Electro Spirit.\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33mPlease provide a deck that is effective in the current meta, with a focus on Wizard Control.\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/tracing/fluent.py:250\u001b[39m, in \u001b[36m_wrap_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro.send(fn(*args, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/tracing/fluent.py:239\u001b[39m, in \u001b[36m_wrap_function.<locals>._WrappingContext.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28mself\u001b[39m.coro.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/tracing/fluent.py:215\u001b[39m, in \u001b[36m_wrap_function.<locals>._WrappingContext._wrapping_logic\u001b[39m\u001b[34m(fn, args, kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m inputs = capture_function_input_args(fn, args, kwargs)\n\u001b[32m    214\u001b[39m span.set_inputs(inputs)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m result = \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[32m    216\u001b[39m span.set_outputs(result)\n\u001b[32m    218\u001b[39m set_chat_attributes_special_case(span, inputs=inputs, outputs=result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/tracing/fluent.py:251\u001b[39m, in \u001b[36m_wrap_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro.send(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 237\u001b[39m, in \u001b[36mask_agent\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m    Function to ask for deck advice from the OpenAI API.\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    199\u001b[39m     instruction_prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[33m## Identity\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[33mYou are a Clash Royale deck-building assistant. Provide concise, practical deck-building advice.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m \u001b[33m```\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     content = response.output_text\n\u001b[32m    246\u001b[39m     deck_data = json.loads(content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:484\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    482\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/openai/autolog.py:237\u001b[39m, in \u001b[36mpatched_call\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Execute the original function\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     raw_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.log_traces:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:475\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    472\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:426\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    424\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:472\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    469\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    471\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:684\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    655\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    682\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    683\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/H.S/m13_mlops/monitoring-for-modern-ai-and-mlops/.venv/lib/python3.12/site-packages/openai/_base_client.py:1001\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1000\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising connection error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1003\u001b[39m log.debug(\n\u001b[32m   1004\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1005\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1009\u001b[39m     response.headers,\n\u001b[32m   1010\u001b[39m )\n\u001b[32m   1011\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mAPIConnectionError\u001b[39m: Connection error."
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://0.0.0.0:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=7b0aa3ca27784a2c9165d860a8be0b63&amp;experiment_id=419303892693814413&amp;version=3.1.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=7b0aa3ca27784a2c9165d860a8be0b63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_agent(\"\"\"\n",
    "I need a deck for Hog Cycle Control. I have the following cards available: Mega Knight, Firecracker, Tesla, Hog Rider, Skeletons, Ice Spirit, Fireball, The Log.\n",
    "Please provide a deck that is effective in the current meta, with a focus on Hog Cycle Control.\n",
    "\"\"\")\n",
    "\n",
    "ask_agent(\"\"\"\n",
    "I want to counter a Giant deck with a Hog Cycle Control deck. I have the following cards available: Mega Knight, Firecracker, Tesla, Hog Rider, Skeletons, Ice Spirit, Fireball, The Log.\n",
    "Please provide a deck that is effective in the current meta, with a focus on Hog Cycle Control.\n",
    "\"\"\")\n",
    "\n",
    "ask_agent(\"\"\"\n",
    "I need a deck for Wizard Control. I have the following cards available: Giant, Mini P.E.K.K.A, Wizard, Arrows, Bomber, Musketeer, Valkyrie, Electro Spirit.\n",
    "Please provide a deck that is effective in the current meta, with a focus on Wizard Control.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a22df5",
   "metadata": {},
   "source": [
    "# Monitoring LLM Evaluation Results\n",
    "\n",
    "This section monitors the quality and relevance of the LLM evaluation results to detect potential issues such as:\n",
    "- Inconsistent scoring patterns\n",
    "- Evaluation drift over time\n",
    "- Outlier scores that may indicate model issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "369b5176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Evaluation monitoring database created\n",
      "🔍 Monitoring 23 evaluation runs...\n",
      "\n",
      "📊 LLM Evaluation Monitoring Report:\n",
      "   • Total evaluations: 23\n",
      "   • Average overall score: 7.64\n",
      "   • Score variance: 0.229\n",
      "   • Low scores detected: 0\n",
      "   • System status: HEALTHY\n",
      "✅ Monitoring metrics logged to database for Grafana visualization\n",
      "   Database URI: postgresql+psycopg2://admin:admin@127.0.0.1:5432/monitoring_db\n",
      "   Table: llm_evaluation_monitoring\n",
      "\n",
      "📈 Evidently Report Generated:\n",
      "   • Reference evaluations: 10\n",
      "   • Current evaluations: 11\n",
      "   • Drift analysis completed\n",
      "\n",
      "📈 Evidently Report Generated:\n",
      "   • Reference evaluations: 10\n",
      "   • Current evaluations: 11\n",
      "   • Drift analysis completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pendulum\n",
    "from sqlalchemy import Boolean, Column, Float, Integer, String, DateTime\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from evidently import Dataset\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset\n",
    "import warnings\n",
    "\n",
    "# Suppress all numpy warnings to avoid division by zero and invalid value warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(all='ignore')  # Suppress numpy errors/warnings\n",
    "\n",
    "# Database setup for Grafana\n",
    "USER = \"admin\"\n",
    "PASSWORD = \"admin\"\n",
    "MONITORING_DB_URI = f\"postgresql+psycopg2://{USER}:{PASSWORD}@127.0.0.1:5432/monitoring_db\"\n",
    "\n",
    "# Create database table for LLM evaluation monitoring\n",
    "Base = declarative_base()\n",
    "\n",
    "class LLMEvaluationTable(Base):\n",
    "    \"\"\"Table for LLM evaluation monitoring metrics.\"\"\"\n",
    "    __tablename__ = \"llm_evaluation_monitoring\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    timestamp = Column(Float)\n",
    "    avg_overall_score = Column(Float)\n",
    "    avg_defense_score = Column(Float)\n",
    "    avg_attack_score = Column(Float)\n",
    "    avg_synergy_score = Column(Float)\n",
    "    avg_versatility_score = Column(Float)\n",
    "    avg_difficulty_score = Column(Float)\n",
    "    score_variance = Column(Float)\n",
    "    low_score_count = Column(Integer)\n",
    "    total_evaluations = Column(Integer)\n",
    "    system_health_status = Column(String)\n",
    "\n",
    "def create_monitoring_db():\n",
    "    \"\"\"Create monitoring database tables.\"\"\"\n",
    "    engine = create_engine(MONITORING_DB_URI)\n",
    "    Base.metadata.create_all(engine)\n",
    "    print(\"✅ LLM Evaluation monitoring database created\")\n",
    "\n",
    "def get_llm_monitoring_metrics(runs_df):\n",
    "    \"\"\"Extract monitoring metrics from MLflow runs with robust error handling.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Calculate averages and variance for each metric with safety checks\n",
    "    eval_metrics = ['eval_overall', 'eval_defense', 'eval_attack', 'eval_synergy', 'eval_versatility', 'eval_difficulty']\n",
    "    \n",
    "    for metric in eval_metrics:\n",
    "        col_name = f'metrics.{metric}'\n",
    "        if col_name in runs_df.columns:\n",
    "            values = runs_df[col_name].dropna()\n",
    "            if len(values) > 0:\n",
    "                # Safe mean calculation\n",
    "                mean_val = values.mean()\n",
    "                if pd.isna(mean_val) or not np.isfinite(mean_val):\n",
    "                    mean_val = 0.0\n",
    "                metrics[f'avg_{metric}_score'] = mean_val\n",
    "    \n",
    "    # Calculate overall variance (instability indicator) with comprehensive safety\n",
    "    overall_scores = runs_df['metrics.eval_overall'].dropna() if 'metrics.eval_overall' in runs_df.columns else pd.Series()\n",
    "    if len(overall_scores) > 1:\n",
    "        try:\n",
    "            variance = overall_scores.var()\n",
    "            if pd.isna(variance) or not np.isfinite(variance):\n",
    "                variance = 0.0\n",
    "            metrics['score_variance'] = variance\n",
    "        except (ZeroDivisionError, RuntimeWarning):\n",
    "            metrics['score_variance'] = 0.0\n",
    "    else:\n",
    "        metrics['score_variance'] = 0.0\n",
    "    \n",
    "    # Count low scores (quality issues) with comprehensive safety\n",
    "    low_threshold = 3.0\n",
    "    low_score_count = 0\n",
    "    for metric in eval_metrics:\n",
    "        col_name = f'metrics.{metric}'\n",
    "        if col_name in runs_df.columns:\n",
    "            try:\n",
    "                values = runs_df[col_name].dropna()\n",
    "                if len(values) > 0:\n",
    "                    # Safe comparison that handles NaN values\n",
    "                    low_scores = np.sum(values < low_threshold)\n",
    "                    if pd.isna(low_scores) or not np.isfinite(low_scores):\n",
    "                        low_scores = 0\n",
    "                    low_score_count += int(low_scores)\n",
    "            except (TypeError, ValueError):\n",
    "                continue  # Skip problematic columns\n",
    "    \n",
    "    metrics['low_score_count'] = low_score_count\n",
    "    metrics['total_evaluations'] = len(runs_df)\n",
    "    \n",
    "    # Determine system health with ultra-safe division\n",
    "    avg_overall = metrics.get('avg_eval_overall_score', 0)\n",
    "    if pd.isna(avg_overall) or not np.isfinite(avg_overall):\n",
    "        avg_overall = 0.0\n",
    "    \n",
    "    try:\n",
    "        if avg_overall >= 7.0:\n",
    "            metrics['system_health_status'] = 'HEALTHY'\n",
    "        elif avg_overall >= 5.0:\n",
    "            metrics['system_health_status'] = 'CAUTION'\n",
    "        else:\n",
    "            metrics['system_health_status'] = 'CRITICAL'\n",
    "    except (TypeError, ValueError):\n",
    "        metrics['system_health_status'] = 'UNKNOWN'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize monitoring database\n",
    "try:\n",
    "    create_monitoring_db()\n",
    "    \n",
    "    # Retrieve MLflow experiment data\n",
    "    experiment = mlflow.get_experiment_by_name(\"assignment-5-evaluate-llm\")\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    \n",
    "    if len(runs) > 0:\n",
    "        print(f\"🔍 Monitoring {len(runs)} evaluation runs...\")\n",
    "        \n",
    "        # Extract monitoring metrics\n",
    "        monitoring_metrics = get_llm_monitoring_metrics(runs)\n",
    "        \n",
    "        # Display current monitoring status\n",
    "        print(\"\\n📊 LLM Evaluation Monitoring Report:\")\n",
    "        print(f\"   • Total evaluations: {monitoring_metrics['total_evaluations']}\")\n",
    "        print(f\"   • Average overall score: {monitoring_metrics.get('avg_eval_overall_score', 0):.2f}\")\n",
    "        print(f\"   • Score variance: {monitoring_metrics['score_variance']:.3f}\")\n",
    "        print(f\"   • Low scores detected: {monitoring_metrics['low_score_count']}\")\n",
    "        print(f\"   • System status: {monitoring_metrics['system_health_status']}\")\n",
    "        \n",
    "        # Log metrics to database for Grafana\n",
    "        engine = create_engine(MONITORING_DB_URI)\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "        \n",
    "        # Create monitoring record - convert NumPy types to Python types\n",
    "        timestamp = pendulum.now().timestamp()\n",
    "        monitoring_record = LLMEvaluationTable(\n",
    "            timestamp=timestamp,\n",
    "            avg_overall_score=float(monitoring_metrics.get('avg_eval_overall_score', 0)),\n",
    "            avg_defense_score=float(monitoring_metrics.get('avg_eval_defense_score', 0)),\n",
    "            avg_attack_score=float(monitoring_metrics.get('avg_eval_attack_score', 0)),\n",
    "            avg_synergy_score=float(monitoring_metrics.get('avg_eval_synergy_score', 0)),\n",
    "            avg_versatility_score=float(monitoring_metrics.get('avg_eval_versatility_score', 0)),\n",
    "            avg_difficulty_score=float(monitoring_metrics.get('avg_eval_difficulty_score', 0)),\n",
    "            score_variance=float(monitoring_metrics['score_variance']),\n",
    "            low_score_count=int(monitoring_metrics['low_score_count']),\n",
    "            total_evaluations=int(monitoring_metrics['total_evaluations']),\n",
    "            system_health_status=str(monitoring_metrics['system_health_status'])\n",
    "        )\n",
    "        \n",
    "        session.add(monitoring_record)\n",
    "        session.commit()\n",
    "        session.close()\n",
    "        \n",
    "        print(f\"✅ Monitoring metrics logged to database for Grafana visualization\")\n",
    "        print(f\"   Database URI: {MONITORING_DB_URI}\")\n",
    "        print(f\"   Table: llm_evaluation_monitoring\")\n",
    "        \n",
    "        # Generate Evidently report for detailed analysis\n",
    "        if len(runs) >= 2:\n",
    "            # Create a simple dataset for drift analysis on evaluation scores\n",
    "            eval_data = runs[['metrics.eval_overall', 'metrics.eval_defense', 'metrics.eval_attack', \n",
    "                            'metrics.eval_synergy', 'metrics.eval_versatility', 'metrics.eval_difficulty']].dropna()\n",
    "            \n",
    "            if len(eval_data) >= 2:\n",
    "                # Split data into reference (first half) and current (second half)\n",
    "                split_idx = len(eval_data) // 2\n",
    "                reference_data = eval_data.iloc[:split_idx]\n",
    "                current_data = eval_data.iloc[split_idx:]\n",
    "                \n",
    "                # Create Evidently datasets\n",
    "                reference_dataset = Dataset.from_pandas(reference_data)\n",
    "                current_dataset = Dataset.from_pandas(current_data)\n",
    "                \n",
    "                # Create report to detect evaluation drift\n",
    "                report = Report([DataDriftPreset()])\n",
    "                report.run(current_data=current_dataset, reference_data=reference_dataset)\n",
    "                \n",
    "                print(f\"\\n📈 Evidently Report Generated:\")\n",
    "                print(f\"   • Reference evaluations: {len(reference_data)}\")\n",
    "                print(f\"   • Current evaluations: {len(current_data)}\")\n",
    "                print(f\"   • Drift analysis completed\")\n",
    "    else:\n",
    "        print(\"❌ No evaluation runs found in MLflow experiment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error setting up monitoring: {e}\")\n",
    "    print(\"Make sure PostgreSQL is running and accessible\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
